{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219d3633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from bidict import bidict\n",
    "from copy import copy\n",
    "from itertools import combinations, permutations\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc567cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_features.csv', index_col='match_id_hash')\n",
    "target = pd.read_csv('data/train_targets.csv', index_col='match_id_hash')['radiant_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cbda235",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['game_mode'] = (train['game_mode'] == 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X1, y_train, y1 = train_test_split(train, target, test_size=0.4, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X1, y1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2460c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"kills\", \"deaths\", \"assists\", \"lh\", \"denies\", \"gold\", \"xp\", \"level\", \"health\", \"max_health\", \"max_mana\"]\n",
    "radiant_attributes = [f\"r{i}_{j}\" for i in range(1,6) for j in attributes]\n",
    "dire_attributes = [f\"d{i}_{j}\" for i in range(1,6) for j in attributes]\n",
    "game_attributes = ['game_time', 'objectives_len', 'chat_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3de6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_valid_scaled = X_valid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999c82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b59f6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled[\n",
    "    game_attributes + radiant_attributes + dire_attributes\n",
    "] = scale.fit_transform(X_train[game_attributes + radiant_attributes + dire_attributes])\n",
    "X_test_scaled[\n",
    "    game_attributes + radiant_attributes + dire_attributes\n",
    "] = scale.transform(X_test[game_attributes + radiant_attributes + dire_attributes])\n",
    "X_valid_scaled[\n",
    "    game_attributes + radiant_attributes + dire_attributes\n",
    "] = scale.transform(X_valid[game_attributes + radiant_attributes + dire_attributes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7acebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hero_dummies(heroes):\n",
    "    n = heroes.shape[1]\n",
    "    return sum(pd.get_dummies(heroes.iloc[:,i]) for i in range(n))\n",
    "    \n",
    "    \n",
    "class HeroBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        heroes_binarized_r = sum(pd.get_dummies(X[f\"r{i}_hero_id\"]) for i in range(1,6))\n",
    "        heroes_binarized_d = sum(pd.get_dummies(X[f\"d{i}_hero_id\"]) for i in range(1,6))\n",
    "        X1 = pd.concat([X, heroes_binarized_r, heroes_binarized_d], axis = 1)\n",
    "        X1 = X1.drop([f\"r{i}_hero_id\" for i in range(1,6)] + [f\"d{i}_hero_id\" for i in range(1,6)], axis=1)\n",
    "        return X1\n",
    "\n",
    "\n",
    "class DummiesGetter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_dummies = pd.concat([X] + [pd.get_dummies(X[c]) for c in self.columns], axis=1)\n",
    "        return X_dummies.drop(self.columns, axis=1)\n",
    "\n",
    "\n",
    "class HeroRemapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.columns = [f\"r{i}_hero_id\" for i in range(1,6)] + [f\"d{i}_hero_id\" for i in range(1,6)]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        hero_idx = np.sort(X[self.columns[0]].unique())\n",
    "        self.hero_idx_map = bidict(zip(hero_idx, range(len(hero_idx))))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_mapped = copy(X)\n",
    "        for c in self.columns:\n",
    "            X_mapped[c] = X_mapped[c].map(self.hero_idx_map)\n",
    "        return X_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e0e95c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplets_to_adjacency(edges):\n",
    "    rows, cols, vals = edges.T\n",
    "    adj = np.zeros([int(np.max(rows))+1, int(np.max(cols))+1])\n",
    "    adj[rows.astype(int), cols.astype(int)] = vals\n",
    "    return adj\n",
    "\n",
    "\n",
    "def get_adjacency_matrix(df):\n",
    "    pair_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        pair_list.extend(permutations(row, 2))\n",
    "    counter = Counter(pair_list)\n",
    "    edges = np.array([(*key, value) for key, value in counter.items()])\n",
    "    return triplets_to_adjacency(edges)\n",
    "\n",
    "\n",
    "def context_matrix(data):\n",
    "    def pmi(i, j, n_ij):\n",
    "        n_i = n_counts[i]\n",
    "        n_j = n_counts[j]\n",
    "        return log2((n*n_ij)/(n_i*n_j))\n",
    "\n",
    "    n = data.shape[0]\n",
    "    n_counts = get_hero_dummies(data).sum().to_dict()\n",
    "    \n",
    "    mate_pair_list = []\n",
    "    enemy_pair_list = []\n",
    "    for i, row in data.iterrows():\n",
    "        radiant, dire = row[:5], row[5:]\n",
    "        # add all pairs of teammates\n",
    "        mate_pair_list.extend(permutations(radiant, 2))\n",
    "        mate_pair_list.extend(permutations(dire, 2))\n",
    "        # add all pairs of enemies\n",
    "        for h in radiant:\n",
    "            enemy_pair_list.extend([(h, e) for e in dire])\n",
    "        for h in dire:\n",
    "            enemy_pair_list.extend([(h, e) for e in radiant])\n",
    "\n",
    "    mate_counter = Counter(mate_pair_list)\n",
    "    enemy_counter = Counter(enemy_pair_list)\n",
    "    \n",
    "    mate_edges = np.array([(*key, pmi(*key, value)) for key, value in mate_counter.items()])\n",
    "    mate_adj = triplets_to_adjacency(mate_edges)\n",
    "    enemy_edges = np.array([(*key, pmi(*key, value*4/5)) for key, value in enemy_counter.items()])\n",
    "    enemy_adj = triplets_to_adjacency(enemy_edges)\n",
    "\n",
    "    return np.hstack((mate_adj, enemy_adj))\n",
    "\n",
    "    \n",
    "class HeroFactorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_factors=10):\n",
    "        self.n_factors = n_factors\n",
    "        self.columns = [f\"r{i}_hero_id\" for i in range(1,6)] + [f\"d{i}_hero_id\" for i in range(1,6)]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        heroes = X[self.columns]\n",
    "        self.context = context_matrix(heroes)\n",
    "        u, sigma, vt = np.linalg.svd(self.context)\n",
    "\n",
    "        self.embeddings = StandardScaler().fit_transform(u[:, :self.n_factors])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        radiant = np.zeros((X.shape[0], self.n_factors))\n",
    "        for radiant_hero in self.columns[:5]:\n",
    "            radiant += self.embeddings[X[radiant_hero], :]\n",
    "            \n",
    "        dire = np.zeros((X.shape[0], self.n_factors))\n",
    "        for dire_hero in self.columns[:5]:\n",
    "            dire += self.embeddings[X[dire_hero], :]\n",
    "        \n",
    "        radiant_df = pd.DataFrame(radiant, columns=[f'r_feat_{i}' for i in range(self.n_factors)], index=X.index)\n",
    "        dire_df = pd.DataFrame(dire, columns=[f'd_feat_{i}' for i in range(self.n_factors)], index=X.index)\n",
    "        return pd.concat((X, radiant_df, dire_df), axis=1).drop(self.columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e9e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_df(data, vars, n_shuffles=10):\n",
    "    data_shuffle = [data.copy() for i in range(n_shuffles)]\n",
    "    perm = list(permutations(range(1,6)))\n",
    "    perm_idx = np.random.choice(len(perm), size=n_shuffles).tolist()\n",
    "    for s, idx in enumerate((perm[i] for i in perm_idx)):\n",
    "        for var in vars:\n",
    "            data_shuffle[s][[f'r{i}_{var}' for i in range(1,6)]] = data_shuffle[s][[f'r{i}_{var}' for i in idx]]\n",
    "            data_shuffle[s][[f'd{i}_{var}' for i in range(1,6)]] = data_shuffle[s][[f'd{i}_{var}' for i in idx]]\n",
    "    \n",
    "    return pd.concat([data] + data_shuffle, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb47794",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['hero_id', 'kills', 'deaths', 'assists', 'denies',\n",
    "       'gold', 'lh', 'xp', 'health', 'max_health',\n",
    "       'max_mana', 'level', 'x', 'y', 'stuns',\n",
    "       'creeps_stacked', 'camps_stacked', 'rune_pickups',\n",
    "       'firstblood_claimed', 'teamfight_participation',\n",
    "       'towers_killed', 'roshans_killed', 'obs_placed',\n",
    "       'sen_placed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137798ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ppl = Pipeline([\n",
    "    (\"dum\", DummiesGetter(['lobby_type'])),\n",
    "    (\"bin\", HeroBinarizer())\n",
    "])\n",
    "\n",
    "X_train_default = default_ppl.fit_transform(X_train_scaled)\n",
    "X_train_default_shuffle = default_ppl.fit_transform(shuffle_df(X_train_scaled, vars=vars, n_shuffles=10))\n",
    "X_valid_default = default_ppl.transform(X_valid_scaled)\n",
    "X_test_default = default_ppl.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4d0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_ppl = Pipeline([\n",
    "    (\"map\", HeroRemapper()),\n",
    "    (\"dum\", DummiesGetter(['lobby_type'])),\n",
    "    (\"fact\", HeroFactorizer(n_factors=20))\n",
    "])\n",
    "\n",
    "X_train_factor = factor_ppl.fit_transform(X_train_scaled)\n",
    "X_train_factor_shuffle = factor_ppl.fit_transform(shuffle_df(X_train_scaled, vars=vars, n_shuffles=10))\n",
    "X_valid_factor = factor_ppl.transform(X_valid_scaled)\n",
    "X_test_factor = factor_ppl.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0916fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_y(y, n_shuffles=10):\n",
    "    return pd.concat([y for _ in range(n_shuffles+1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73c2ab37",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "907059ca",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b383152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794928077535013\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train_default, y_train)\n",
    "y_valid_predicted = clf.predict_proba(X_valid_default)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75421688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7714842242767577\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train_factor, y_train)\n",
    "y_valid_predicted = clf.predict_proba(X_valid_factor)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f232e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7855574573634092\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train_default_shuffle, stack_y(y_train, 10))\n",
    "y_valid_predicted = clf.predict_proba(X_valid_default)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7082e1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7760828292007322\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train_factor_shuffle, stack_y(y_train, 10))\n",
    "y_valid_predicted = clf.predict_proba(X_valid_factor)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a443cd04",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58ddb960",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7841882894196972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gbc.fit(X_train_default, y_train)\n",
    "y_valid_predicted = gbc.predict_proba(X_valid_default)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49b7aaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7789410273735534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gbc.fit(X_train_factor, y_train)\n",
    "y_valid_predicted = gbc.predict_proba(X_valid_factor)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98b8e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7879724356856861\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gbc.fit(X_train_default_shuffle, stack_y(y_train, 10))\n",
    "y_valid_predicted = gbc.predict_proba(X_valid_default)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f15e53c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833206329187106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "gbc.fit(X_train_factor_shuffle, stack_y(y_train, 10))\n",
    "y_valid_predicted = gbc.predict_proba(X_valid_factor)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02cc7e23",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "003cc42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7984161496299009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_default, y_train)\n",
    "y_valid_predicted = lr.predict_proba(X_valid_default)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c0d4f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802056524825278\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_default_shuffle, stack_y(y_train, 10))\n",
    "y_valid_predicted = lr.predict_proba(X_valid_default)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8e1a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7918955139605657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_factor, y_train)\n",
    "y_valid_predicted = lr.predict_proba(X_valid_factor)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d349806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7920784432280006\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train_factor_shuffle, stack_y(y_train, 10))\n",
    "y_valid_predicted = lr.predict_proba(X_valid_factor)\n",
    "print(roc_auc_score(y_valid, y_valid_predicted[:, 1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 08:09:04) [Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "89efc078f48b783e4ce3996c23901b3332d64c328e3b1a6b67b0fdf1b6ac19ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
